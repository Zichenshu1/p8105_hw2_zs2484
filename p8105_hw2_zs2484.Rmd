---
title: "Homework 2"
author: "Zichen Shu"
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r, warning = FALSE}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

```{r, message = FALSE, warning = FALSE}
precip_2018 =
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

```{r}
precip_2017 =
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation

```{r}
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_df2 = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains indormation from the Mr. Trash Wheel collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.

The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`

The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.



## Problem 2

##### Read in the subway dataset.
```{r, warning = FALSE, message = FALSE}
subway_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, route1:route11, station_latitude, station_longitude, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"), entry = as.logical(entry))
```

The dataset contains these **`r names(subway_df)`** variables. It consists of **`r nrow(subway_df)`** rows and **`r ncol(subway_df)`** columns. Some of the cleaning steps I have done so far are converting all variable names to lower case and replace the space with underscore, select the required variables and change the "entry" variable to a logical variable. The data is not tidy since the dataset is in "wider" format and route8:11 are double variable.

```{r}
distinct_station = distinct(subway_df, station_name, line, .keep_all = T)

ada_compliance = filter(distinct_station, ada == TRUE)
  

no_vending = filter(subway_df, vending == "NO")
  
entry_no_vending = filter(no_vending, entry == TRUE)
```

There are distinct **`r nrow(distinct_station)`** stations.
There are **`r nrow(ada_compliance)`** stations with ada compliance.
The proportion of station entrances without vending allow entrance is **`r nrow(entry_no_vending)/nrow(no_vending)`**

##### Reformat the route number and route name

```{r}
subway_tidy = 
  mutate(subway_df, route8 = as.character(route8), route9 = as.character(route9), route10 = as.character(route10), route11 = as.character(route11)) %>% 
  pivot_longer(route1:route11, names_to = "route_name", values_to = "route_number") %>% 
  relocate(line, station_name, route_name, route_number)

train_A = 
  distinct(subway_tidy, station_name, line, .keep_all = T) %>% 
  filter(route_number == "A")

train_A_ada = 
  distinct(subway_tidy, station_name, line, .keep_all = T) %>%  
  filter(route_number == "A") %>% 
  filter(ada == TRUE)
```

There are **`r nrow(train_A)`** distinct stations serves the A train. Of the stations that serve the A train, **`r nrow(train_A_ada)`** are ADA compliant.

## Problem 3

##### pols-month.csv dataset
```{r, warning = FALSE, message = FALSE}
pols_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(month = as.double(month), month = month.abb[month]) %>% 
  mutate(president = case_when(prez_gop == "1" ~ "gop", prez_dem == "1" ~ "dem")) %>% 
  select(-prez_dem, -prez_gop, -day)
```

##### snp.csv dataset
```{r, warning = FALSE, message = FALSE}
snp_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>%
  mutate(month = as.double(month), month = month.abb[month]) %>% 
  select(-day) %>% 
  relocate(year, month)
```

##### unemployment_rate.csv dataset
```{r, warning = FALSE, message = FALSE}
unemployment_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment_rate") %>%   janitor::clean_names() %>% 
  mutate(year = as.character(year))
```

##### Merging snp_df into pols_df, then merge unemployment_df

```{r}
pols_snp_df = left_join(pols_df, snp_df, by = c("year" = "year", "month" = "month"))

pols_snp_employment_df = left_join(pols_snp_df, unemployment_df, by = c("year" = "year", "month" = "month"))
```

The pols-month.csv dataset contains **`r names(pols_df)`** variables. The snp.csv dataset contains **`r names(pols_df)`** variables.  The unemployment.csv dataset contains **`r names(unemployment_df)`** variables. The resulting dataset has **`r nrow(pols_snp_employment_df)`** rows and **`r ncol(pols_snp_employment_df)`** columnscx.  The range of year is **`r range(pull(pols_snp_employment_df, year), na.rm = TRUE)`**.  The final dataset is joined by the common keys variables: **year** and **month**.




